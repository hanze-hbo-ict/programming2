{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Programming 4 \u00b6 These pages provide the materials, information, and assignments for the module Programming 4 for the Master Digital Science for Life Science. In this module, we focus on the interesting subject software engineering for machine learning . We will provide some methods and techniques from the field of software engineering and see how we can apply those to data science (and, by extension, life sciences ). We delve in quite some depth into object life-cycle and multiple class interaction , generators and async programming , parallellisation , and design patterns . Specifically, the module contains the following subjects: weeknumber subject(s) 1 Introduction; SOLID; Static Code Analysis 2 OO: Classes and Objects; Constructors and Destructors; Object Lifecycle; Dunders 3 List Comprehensions; Generators; map-reduce; 4 Parallellisation and async programming 5 Putting it all together Assignment \u00b6 During the course, students will work individually on (more or less) weekly assignments. Every week, students are given time to work on these assignments and will give peer feedback on each other's work. Students can improve their elaboration on basis of this feedback. You can find the assignments (all five of them) in the menu on the left. Make a directory for each of the assignments ( assignment1/ , assignment2/ , you get the gist). At the end of the term, the collection of all these elaborations will form a portfolio which will be graded. Should the portfolio be considered insufficient, specific repair assignments will be given. github \u00b6 For this module, the use of github is mandatory. All work must be submitted to github in an orderly fashion \u2013 having a good and consistent git workflow is part of the requirements for the grade. This includes (but is not necessarily limited to) Using a local and remote version of your code base Branching and merging at specific points in your developmen cycle Writing good and informative commit messages Committing often No Notebook \u00b6 Even though we are really a big fan of Jupyter Notebook, in this module use of this tool is strictly forbidden. Writing software for the future means being able to write software that is readable, maintainable and re-usable, software that is ready for production. Thought there is some tooling that makes it possible to put notebooks in production, this is not what they are meant for. The use case for Jupyter Notebooks is exploration and research and in this module we are focussing on software development. A note on the use of AI \u00b6 We expect you to use AI (ChatGPT and image generation tools, at a minimum) in this module. Learning to use AI is an emerging skill and we will provide tutorials about how to do this in an efficient and interesting way. Be aware of the limits of ChatGPT: If you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work and practice. Don't believe anything it says. If it gives you facts, assume them to be wrong and make sure you check them in some other way or reference. You will be responsible for any errors or omissions provided by the tool. AI is a tool, but one that you need to acknowledge using. Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you provided it with. Have a look at this page at apa.org to get an idea about how to reference to ChatGPT. Be thoughtful about when this tool is useful. Don't use it if it isn't appropriate for the case or for the circumstances.","title":"Introduction"},{"location":"index.html#programming-4","text":"These pages provide the materials, information, and assignments for the module Programming 4 for the Master Digital Science for Life Science. In this module, we focus on the interesting subject software engineering for machine learning . We will provide some methods and techniques from the field of software engineering and see how we can apply those to data science (and, by extension, life sciences ). We delve in quite some depth into object life-cycle and multiple class interaction , generators and async programming , parallellisation , and design patterns . Specifically, the module contains the following subjects: weeknumber subject(s) 1 Introduction; SOLID; Static Code Analysis 2 OO: Classes and Objects; Constructors and Destructors; Object Lifecycle; Dunders 3 List Comprehensions; Generators; map-reduce; 4 Parallellisation and async programming 5 Putting it all together","title":"Programming 4"},{"location":"index.html#assignment","text":"During the course, students will work individually on (more or less) weekly assignments. Every week, students are given time to work on these assignments and will give peer feedback on each other's work. Students can improve their elaboration on basis of this feedback. You can find the assignments (all five of them) in the menu on the left. Make a directory for each of the assignments ( assignment1/ , assignment2/ , you get the gist). At the end of the term, the collection of all these elaborations will form a portfolio which will be graded. Should the portfolio be considered insufficient, specific repair assignments will be given.","title":"Assignment"},{"location":"index.html#github","text":"For this module, the use of github is mandatory. All work must be submitted to github in an orderly fashion \u2013 having a good and consistent git workflow is part of the requirements for the grade. This includes (but is not necessarily limited to) Using a local and remote version of your code base Branching and merging at specific points in your developmen cycle Writing good and informative commit messages Committing often","title":"github"},{"location":"index.html#no-notebook","text":"Even though we are really a big fan of Jupyter Notebook, in this module use of this tool is strictly forbidden. Writing software for the future means being able to write software that is readable, maintainable and re-usable, software that is ready for production. Thought there is some tooling that makes it possible to put notebooks in production, this is not what they are meant for. The use case for Jupyter Notebooks is exploration and research and in this module we are focussing on software development.","title":"No Notebook"},{"location":"index.html#a-note-on-the-use-of-ai","text":"We expect you to use AI (ChatGPT and image generation tools, at a minimum) in this module. Learning to use AI is an emerging skill and we will provide tutorials about how to do this in an efficient and interesting way. Be aware of the limits of ChatGPT: If you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work and practice. Don't believe anything it says. If it gives you facts, assume them to be wrong and make sure you check them in some other way or reference. You will be responsible for any errors or omissions provided by the tool. AI is a tool, but one that you need to acknowledge using. Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you provided it with. Have a look at this page at apa.org to get an idea about how to reference to ChatGPT. Be thoughtful about when this tool is useful. Don't use it if it isn't appropriate for the case or for the circumstances.","title":"A note on the use of AI"},{"location":"assignment1.html","text":"Assignment 1: Static code analysis \u00b6 During the plenary part, we discussed the necessity of static code analysis. We looked at the ontology of Python-applications, going from functions to classes to modules to systems. We also had a look at more high-level descriptions of code, using the c4-model to describe any software system. For this assignment, you are required to write a small report of your findings on one of the code bases listed below . This report should be written in a file report.md in the corresponding directory (i.e. assigment1/ ). If you want to include images (which should be considered good practice), please put them in the directory assignment1/imgs . We suggest plantuml to create technical images. Report \u00b6 Start your analysis with a short discription of the code-base: what it does, its intended use-case and public (basically a summary of the project's readme -file). Also give a description of its status on github (number of PR's, issues, pulse etc.). After that, give a high-level overview of the code-base: how is the code organized, what is the architectural setup, dependencies, build strategies etc. Images such as class- or sequence-diagrams are helpful at this level. Next, give a short quantitative description of the code-base: how many LoC, how many functions/methods/classes, how many modules/packages/namespaces, etc. After this overview, you should look in some more depth to your code-base. You can make use of one of the technical tools that are suggested on c4model.com/tooling . Also, run at least one static analysis tool (e.g. pylint , flake8 , sonarqube , bandit , cloc , or a language-specific alternative). Give attention to at least the following items: Complexity metrics for each function/method Code smells Dead code, unused imports Security issues (if any) Conclude with a reflection about the project: what do you think of it, where do you see refactoring candidates and what would your advice be to the ones that made the it. The list \u00b6 Here is the list of projects that you can choose from. If you have another project you would like to analyse, please discuss this with the teacher. Name Language(s) Short desciption url tldr-pages Node/Python (and a lot of markdown) Community driven collection of man-page alternatives https://github.com/tldr-pages/tldr httpie Python CLI: human-friendly HTTP client for the API era https://github.com/httpie/cli glances Python Open-source system cross-platform monitoring tool https://github.com/nicolargo/glances poetry Python Basically a dependency manager manager https://github.com/python-poetry/poetry jq C Lightweight and flexible command-line JSON processor https://github.com/stedolan/jq micromark JavaScript Yet another markdown parser https://github.com/micromark/micromark fizzbuzz-enterprise-edition Java Example (parodie) of over-engineered enterprise code https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition thefuck Python Tool to corrects errors in previous console commands https://github.com/nvbn/thefuck jsonlint JavaScript Yet another json-linter https://github.com/zaach/jsonlint htop C Cross-platform interactive process viewer https://github.com/htop-dev/htop","title":"1. Static code analysis"},{"location":"assignment1.html#assignment-1-static-code-analysis","text":"During the plenary part, we discussed the necessity of static code analysis. We looked at the ontology of Python-applications, going from functions to classes to modules to systems. We also had a look at more high-level descriptions of code, using the c4-model to describe any software system. For this assignment, you are required to write a small report of your findings on one of the code bases listed below . This report should be written in a file report.md in the corresponding directory (i.e. assigment1/ ). If you want to include images (which should be considered good practice), please put them in the directory assignment1/imgs . We suggest plantuml to create technical images.","title":"Assignment 1: Static code analysis"},{"location":"assignment1.html#report","text":"Start your analysis with a short discription of the code-base: what it does, its intended use-case and public (basically a summary of the project's readme -file). Also give a description of its status on github (number of PR's, issues, pulse etc.). After that, give a high-level overview of the code-base: how is the code organized, what is the architectural setup, dependencies, build strategies etc. Images such as class- or sequence-diagrams are helpful at this level. Next, give a short quantitative description of the code-base: how many LoC, how many functions/methods/classes, how many modules/packages/namespaces, etc. After this overview, you should look in some more depth to your code-base. You can make use of one of the technical tools that are suggested on c4model.com/tooling . Also, run at least one static analysis tool (e.g. pylint , flake8 , sonarqube , bandit , cloc , or a language-specific alternative). Give attention to at least the following items: Complexity metrics for each function/method Code smells Dead code, unused imports Security issues (if any) Conclude with a reflection about the project: what do you think of it, where do you see refactoring candidates and what would your advice be to the ones that made the it.","title":"Report"},{"location":"assignment1.html#the-list","text":"Here is the list of projects that you can choose from. If you have another project you would like to analyse, please discuss this with the teacher. Name Language(s) Short desciption url tldr-pages Node/Python (and a lot of markdown) Community driven collection of man-page alternatives https://github.com/tldr-pages/tldr httpie Python CLI: human-friendly HTTP client for the API era https://github.com/httpie/cli glances Python Open-source system cross-platform monitoring tool https://github.com/nicolargo/glances poetry Python Basically a dependency manager manager https://github.com/python-poetry/poetry jq C Lightweight and flexible command-line JSON processor https://github.com/stedolan/jq micromark JavaScript Yet another markdown parser https://github.com/micromark/micromark fizzbuzz-enterprise-edition Java Example (parodie) of over-engineered enterprise code https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition thefuck Python Tool to corrects errors in previous console commands https://github.com/nvbn/thefuck jsonlint JavaScript Yet another json-linter https://github.com/zaach/jsonlint htop C Cross-platform interactive process viewer https://github.com/htop-dev/htop","title":"The list"},{"location":"assignment2.html","text":"Assignment 2: Classes and instances \u00b6 Introduction \u00b6 After the static code analysis, which checked the reading of code-bases, from now on we are going to focus on actually writing code. Photosynthesis is the process by which plants and certain algae convert light energy into chemical energy that can be stored and used to drive the organism's activities. Though different varieties of photosynthesis exist, the overall equation for the type that occurs in plants is as follows: \\(6CO_2 + 6H_2O -> C_6H_{12}O_6 + 6O_2 + energy\\) In this exercise, we are going to create a very simple model of this process. Assignment 1: the Atom class \u00b6 1a. Create a class Atom that is a representation of any atom in the periodic table. Make sure that when a concrete atom is instantiated, it is given its symbol, its atomic number and the number of neutrons in the core. Store those parameters in the created object. 1b. Create a method proton_number that returns the number of protons in the nucleus; make another method mass_number that returns the atom's mass number (the sum of protons and neutrons in the nucleus). Isotopes are types of atoms that have the same number of atomic number but a different number of neutrons in the core. So, e.g. 'normal' hydrogen has 1 proton and no neutrons in its nucleus, but it also comes in the form of deuterium whose nucleus contains a neutron (so it consists of 1 proton and 1 neutron) or even tritium (1 proton and 2 neutrons). 1c. Create a method isotope in the class Atom . When this method is called, the given number of neutrons must be replaced by whatever number is provided to this method (so this is an object mutating method ). 1d. We define an atom A to be less than another atom B if their proton number is the same (i.e. it is the same element) but the mass number of A is less than the mass number of B. Implement the methods that checks whether two isotopes of the same element are equal to each other, or less than or greater than each other. Raise an exception when the check is called with different types of elements. You can use the code below to test your implementation. protium = Atom ( 'H' , 1 , 0 ) deuterium = Atom ( 'H' , 1 , 1 ) oxygen = Atom ( 'O' , 8 , 8 ) tritium = Atom ( 'H' , 1 , 2 ) oxygen . isotope ( 9 ) assert tritium . neutrons == 2 assert tritium . mass_number () == 3 assert protium < deuterium assert deuterium <= tritium assert tritium >= protium print ( oxygen > tritium ) # <-- this should raise an Exception Assignment 2: the Molecule class \u00b6 A molecule is a neutral group of two or more atoms. 2a. Create the class Molecule . When creating an instance of this class, a list of tuples of two values (a pair ) is given. The first element of this pair is the Atom-object, and the second element is the number of atoms of that type that is put into the molecule. Thus, the following code snippet creates a water molecule: hydrogen = Atom ( 'H' , 1 , 1 ) oxygen = Atom ( 'O' , 8 , 8 ) water = Molecule ( [ ( hydrogen , 2 ), ( oxygen , 1 ) ] ) 2b. Make sure that when we print individual molecules, we get something resembling the correct chemical formula (you don't have to take the exact protocol into account). So, e.g. print (water) would render H2O . Make sure that the number 1 is omitted in the representation. 2c In our small implementation, molecules that are created can never change (they are immutable ). However, we can add two molecules together in order to create a new molecule. Implement this method in the class Molecule . Creating molecules this way is, of course, not really possible. However, because of educational reasons, we pretend that this is an ok way to work. You can use the code below to test your implementation: hydrogen = Atom ( 'H' , 1 , 0 ) carbon = Atom ( 'C' , 6 , 6 ) oxygen = Atom ( 'O' , 8 , 8 ) water = Molecule ( [ ( hydrogen , 2 ), ( oxygen , 1 ) ] ) co2 = Molecule ( [ ( carbon , 1 ), ( oxygen , 2 ) ]) print ( water ) # H2O print ( co2 ) # CO2 print ( water + co2 ) # H2OCO2 Assignment 3: The Chloroplast class \u00b6 As a final assignment, we are going to make a ( very, very ) simplified version of the photosynthesis process; basically, we are only going to implement the formula stated above. 3a. Create the class Chloroplast . When creating objects of this type, make sure two fields water and co2 are initialised at value 0 . 3b. Implement the following functionality: make a method add_molecule in which we can add water or carbon dioxide molecules. When we add either of them, the corresponding field is incremented by one. When we add something else than water or carbon dioxide, a ValueError is raised, but the program continues to function. If nothing else happens, this method returns an empty list 3c. When we have added a total of 6 CO2-molecules and 12 H2O-molecules, we start of the photosyntheses. We decrease the fields water and co2 with 6 and 12 respectively and create two new molecules: C6H12O6 and O2 (and energy, we we ignore that in this exercise). In this case, the method returns a list of tuples: 1 molecule of sugar and 6 molecules of oxygen (as per the general formula stated above). 3d. Make sure that when we print this instance of chloroplast, we get an idea of how many molecules of water and CO2 are already stored in it. You can use the following script to check your implementation water = Molecule ( [ ( hydrogen , 2 ), ( oxygen , 1 ) ] ) co2 = Molecule ( [ ( carbon , 1 ), ( oxygen , 2 ) ]) demo = Chloroplast () els = [ water , co2 ] while ( True ): print ( ' \\n What molecule would you like to add?' ) print ( '[1] Water' ) print ( '[2] carbondioxyde' ) print ( 'Please enter your choice: ' , end = '' ) try : choice = int ( input ()) res = demo . add_molecule ( els [ choice - 1 ]) if ( len ( res ) == 0 ): print ( demo ) else : print ( ' \\n === Photosynthesis!' ) print ( res ) print ( demo ) except Exception : print ( ' \\n === That is not a valid choice.' )","title":"2. Multiple Class Interaction"},{"location":"assignment2.html#assignment-2-classes-and-instances","text":"","title":"Assignment 2: Classes and instances"},{"location":"assignment2.html#introduction","text":"After the static code analysis, which checked the reading of code-bases, from now on we are going to focus on actually writing code. Photosynthesis is the process by which plants and certain algae convert light energy into chemical energy that can be stored and used to drive the organism's activities. Though different varieties of photosynthesis exist, the overall equation for the type that occurs in plants is as follows: \\(6CO_2 + 6H_2O -> C_6H_{12}O_6 + 6O_2 + energy\\) In this exercise, we are going to create a very simple model of this process.","title":"Introduction"},{"location":"assignment2.html#assignment-1-the-atom-class","text":"1a. Create a class Atom that is a representation of any atom in the periodic table. Make sure that when a concrete atom is instantiated, it is given its symbol, its atomic number and the number of neutrons in the core. Store those parameters in the created object. 1b. Create a method proton_number that returns the number of protons in the nucleus; make another method mass_number that returns the atom's mass number (the sum of protons and neutrons in the nucleus). Isotopes are types of atoms that have the same number of atomic number but a different number of neutrons in the core. So, e.g. 'normal' hydrogen has 1 proton and no neutrons in its nucleus, but it also comes in the form of deuterium whose nucleus contains a neutron (so it consists of 1 proton and 1 neutron) or even tritium (1 proton and 2 neutrons). 1c. Create a method isotope in the class Atom . When this method is called, the given number of neutrons must be replaced by whatever number is provided to this method (so this is an object mutating method ). 1d. We define an atom A to be less than another atom B if their proton number is the same (i.e. it is the same element) but the mass number of A is less than the mass number of B. Implement the methods that checks whether two isotopes of the same element are equal to each other, or less than or greater than each other. Raise an exception when the check is called with different types of elements. You can use the code below to test your implementation. protium = Atom ( 'H' , 1 , 0 ) deuterium = Atom ( 'H' , 1 , 1 ) oxygen = Atom ( 'O' , 8 , 8 ) tritium = Atom ( 'H' , 1 , 2 ) oxygen . isotope ( 9 ) assert tritium . neutrons == 2 assert tritium . mass_number () == 3 assert protium < deuterium assert deuterium <= tritium assert tritium >= protium print ( oxygen > tritium ) # <-- this should raise an Exception","title":"Assignment 1: the Atom class"},{"location":"assignment2.html#assignment-2-the-molecule-class","text":"A molecule is a neutral group of two or more atoms. 2a. Create the class Molecule . When creating an instance of this class, a list of tuples of two values (a pair ) is given. The first element of this pair is the Atom-object, and the second element is the number of atoms of that type that is put into the molecule. Thus, the following code snippet creates a water molecule: hydrogen = Atom ( 'H' , 1 , 1 ) oxygen = Atom ( 'O' , 8 , 8 ) water = Molecule ( [ ( hydrogen , 2 ), ( oxygen , 1 ) ] ) 2b. Make sure that when we print individual molecules, we get something resembling the correct chemical formula (you don't have to take the exact protocol into account). So, e.g. print (water) would render H2O . Make sure that the number 1 is omitted in the representation. 2c In our small implementation, molecules that are created can never change (they are immutable ). However, we can add two molecules together in order to create a new molecule. Implement this method in the class Molecule . Creating molecules this way is, of course, not really possible. However, because of educational reasons, we pretend that this is an ok way to work. You can use the code below to test your implementation: hydrogen = Atom ( 'H' , 1 , 0 ) carbon = Atom ( 'C' , 6 , 6 ) oxygen = Atom ( 'O' , 8 , 8 ) water = Molecule ( [ ( hydrogen , 2 ), ( oxygen , 1 ) ] ) co2 = Molecule ( [ ( carbon , 1 ), ( oxygen , 2 ) ]) print ( water ) # H2O print ( co2 ) # CO2 print ( water + co2 ) # H2OCO2","title":"Assignment 2: the Molecule class"},{"location":"assignment2.html#assignment-3-the-chloroplast-class","text":"As a final assignment, we are going to make a ( very, very ) simplified version of the photosynthesis process; basically, we are only going to implement the formula stated above. 3a. Create the class Chloroplast . When creating objects of this type, make sure two fields water and co2 are initialised at value 0 . 3b. Implement the following functionality: make a method add_molecule in which we can add water or carbon dioxide molecules. When we add either of them, the corresponding field is incremented by one. When we add something else than water or carbon dioxide, a ValueError is raised, but the program continues to function. If nothing else happens, this method returns an empty list 3c. When we have added a total of 6 CO2-molecules and 12 H2O-molecules, we start of the photosyntheses. We decrease the fields water and co2 with 6 and 12 respectively and create two new molecules: C6H12O6 and O2 (and energy, we we ignore that in this exercise). In this case, the method returns a list of tuples: 1 molecule of sugar and 6 molecules of oxygen (as per the general formula stated above). 3d. Make sure that when we print this instance of chloroplast, we get an idea of how many molecules of water and CO2 are already stored in it. You can use the following script to check your implementation water = Molecule ( [ ( hydrogen , 2 ), ( oxygen , 1 ) ] ) co2 = Molecule ( [ ( carbon , 1 ), ( oxygen , 2 ) ]) demo = Chloroplast () els = [ water , co2 ] while ( True ): print ( ' \\n What molecule would you like to add?' ) print ( '[1] Water' ) print ( '[2] carbondioxyde' ) print ( 'Please enter your choice: ' , end = '' ) try : choice = int ( input ()) res = demo . add_molecule ( els [ choice - 1 ]) if ( len ( res ) == 0 ): print ( demo ) else : print ( ' \\n === Photosynthesis!' ) print ( res ) print ( demo ) except Exception : print ( ' \\n === That is not a valid choice.' )","title":"Assignment 3: The Chloroplast class"},{"location":"assignment3.html","text":"Assignment 3: List comprehensions and generators \u00b6 tbd","title":"3. List comprehensions and generators"},{"location":"assignment3.html#assignment-3-list-comprehensions-and-generators","text":"tbd","title":"Assignment 3: List comprehensions and generators"},{"location":"assignment4.html","text":"Assignment 4: Parallellisation \u00b6 Introduction \u00b6 In the plenairy part we have discussed how you can make use of Python's multiprocessor module to distribute the computation of your problem over multiple cores on your CPU. We have seen how this increased performances when you are working with a lot of data, or when you need to do complex calculations. Even though the multiprocessor module is quite complex, the basic workings of it is quite simple. You provide your code with the number of cores you wish to use, some data you want to work with and a function that needs to be called for all the elements of your data. You use the function map for this minimal working example. For easy reference, the relevant portion of the code of the plenairy part is repeated below: import multiprocessing as mp with mp . Pool () as p : res = p . map ( sum_squared , numbers ) In this exercise, we are going to determine the fluctuation of CG-pairs over the genome of an organism. To do this, we need to count the amount of CG in (overlapping or non-overlapping) 'windows' (e.g. 10_000bp). We do this both in a sequential and in a non-sequential way, keeping track of the time it takes in both cases. Assignment \u00b6 Download the genome of the E.coli . Write a Python-program that accepts a command-line argument -w, --window_size that represents the window-size \ud83e\udd2f with which the program flows over the genome, returning the percentage of CG in that window: > python count.py -w 10_000 | head 00000 -10000: 0 .521 10000 -20000: 0 .499 20000 -30000: 0 .526 30000 -40000: 0 .532 40000 -50000: 0 .528 50000 -60000: 0 .516 60000 -70000: 0 .556 70000 -80000: 0 .536 80000 -90000: 0 .500 > Write the results to a csv-file.","title":"4. Parallellisation"},{"location":"assignment4.html#assignment-4-parallellisation","text":"","title":"Assignment 4: Parallellisation"},{"location":"assignment4.html#introduction","text":"In the plenairy part we have discussed how you can make use of Python's multiprocessor module to distribute the computation of your problem over multiple cores on your CPU. We have seen how this increased performances when you are working with a lot of data, or when you need to do complex calculations. Even though the multiprocessor module is quite complex, the basic workings of it is quite simple. You provide your code with the number of cores you wish to use, some data you want to work with and a function that needs to be called for all the elements of your data. You use the function map for this minimal working example. For easy reference, the relevant portion of the code of the plenairy part is repeated below: import multiprocessing as mp with mp . Pool () as p : res = p . map ( sum_squared , numbers ) In this exercise, we are going to determine the fluctuation of CG-pairs over the genome of an organism. To do this, we need to count the amount of CG in (overlapping or non-overlapping) 'windows' (e.g. 10_000bp). We do this both in a sequential and in a non-sequential way, keeping track of the time it takes in both cases.","title":"Introduction"},{"location":"assignment4.html#assignment","text":"Download the genome of the E.coli . Write a Python-program that accepts a command-line argument -w, --window_size that represents the window-size \ud83e\udd2f with which the program flows over the genome, returning the percentage of CG in that window: > python count.py -w 10_000 | head 00000 -10000: 0 .521 10000 -20000: 0 .499 20000 -30000: 0 .526 30000 -40000: 0 .532 40000 -50000: 0 .528 50000 -60000: 0 .516 60000 -70000: 0 .556 70000 -80000: 0 .536 80000 -90000: 0 .500 > Write the results to a csv-file.","title":"Assignment"},{"location":"assignment5.html","text":"Assignment 5: A complete project \u00b6 Introduction \u00b6 In this last assignment, you are asked to work on a relative big application which you need to divide in several classes. You are going to develop a small pipeline with several interacting components that work independent of each other. During the development, you need to take into account all the things we talked about in this module. The application you are going to make, makes use of a trained machine learning model, so this assignment is kind of an integration of DS3 with Programming 2. Have a look at the general machine learning development cycle below. Though we will go through all the steps, the focus will be on steps 3, 4, 5 and 6. Step 1: getting and transforming the data \u00b6 For this exercise, we are elaborating on the anomaly detection study case that is part of the unsupervised part of DS3 . Head over to that notebook, study its contents and download the accompanying dataset. You can also find the dataset at Kaggle: https://www.kaggle.com/datasets/nphantawee/pump-sensor-data Use your own dataset You can also use your own dataset, but only if it fulfills the following requirements: There is a logical (ontological, domain-specific) reason why this dataset grows over time, e.g. when more images become available every month, or new prices of something are published every day, or new network connections are delivered every week; The data you already have is large enough (contains enough instances) to be split along the lines described above, i.e. you must be able to train a model on roughly three-fifth of the dataset and test the complete pipeline at least twice on the remaining splits; In order for the model to work correctly, the data needs some kind of non trivial transformation , like removing outliers, or merging, dropping or calculating columns; Every run of the model on new data should result in an interesting plot of the data. Please check this with the teacher. The dataset contains sensor data from 1 April to 31 August 2018. We're going to train the model on the months April, May, and June and then use the trained model to predict the anomalies of the months July and August. Split the original dataset among these lines, so that eventually you have three files. We use the first of these to actually train the model, and then feed the second and third files to this persisted model sequentially. Step 2: create the model and the drawer \u00b6 Using the first of the three splits described above, train one of the models from the notebook, or use your own realisation. Note that in order to do this training, some data-transformations are necessary. Isolate these relevant transformations, so that they can be performed later on the two remaining sets. Train the model on the transformed dataset. Use one of the techniques described on scikit-learn.org to persist the model on your local file system. Transform only the training-data For this exercise, it is imparitive that you perform the data-transformations after you split the original data and only on the training-data. In this way, we can correctly simulate the entering of future data in our pipeline. Study the method plot_sensor_anomolies(sensor, name) that you can find in the notebook . In the current setup, this method can only work if the dataframe df is defined within the scope of the complete notebook (so only if df is a global variable ). Refactor this method so that is independent of any global variables (global variables are bad news in general). Also, change its functionality so that it returns the plot instead of displaying it. Step 4: listening for new data \u00b6 Now that we have trained and saved our model, it is time to put it into production. For this to work, we are going to make another class that looks at a specific directory. When a new data file is uploaded to this directory, this class will load the data in that file, apply the necessary changes and use our model to predict new new values. It then saves the transformed data with the predictions in another directory and removes the original data file. Apart from saving the transformed and enriched data, it will also create images of certain sensors and save those in the img directory \u2013 their filename displaying both the sensor and the timestamp. Have a look at the sequence diagram below to get an idea of what is happening. The whole process need to be logged in a log-file. A typical run will produce the following lines in this log-file: 2024 -06-11 10 :09:32 Found new data file 2024 -06-11 10 :09:32 Loaded the file 2024 -06-11 10 :09:34 Received transformed data 2024 -06-11 10 :09:38 Received predicions 2024 -06-11 10 :09:38 Saving predictions 2024 -06-11 10 :09:40 Saving image2 2018 -07-sensor04.png 2024 -06-11 10 :09:40 Saving image2 2018 -07-sensor51.png 2024 -06-11 10 :09:40 Resuming listening If the new file in the input -directory does not contain data that is eligable for the system, an error needs to be logged to the log-file. This should, however, not break the running of the application. Test your realisation with the two separate data files you have created \u2013 the ones containing the data for July and for August: when you put one of them in the input -directory, the whole cycle should start and create a new data file in the output -directory and a new image in the img -directory. Technical requirements all files and classes should be independent of each other: they should adhere to the SOLID-principles. the application should make use of a file application.json in which the following settings are present: the location of the input -directory the location of the output -directory the location of the img -directory the names of the sensors that needs to be drawn the interval (in seconds) with which the input -directory is checked for new files","title":"5. Final assignment"},{"location":"assignment5.html#assignment-5-a-complete-project","text":"","title":"Assignment 5: A complete project"},{"location":"assignment5.html#introduction","text":"In this last assignment, you are asked to work on a relative big application which you need to divide in several classes. You are going to develop a small pipeline with several interacting components that work independent of each other. During the development, you need to take into account all the things we talked about in this module. The application you are going to make, makes use of a trained machine learning model, so this assignment is kind of an integration of DS3 with Programming 2. Have a look at the general machine learning development cycle below. Though we will go through all the steps, the focus will be on steps 3, 4, 5 and 6.","title":"Introduction"},{"location":"assignment5.html#step-1-getting-and-transforming-the-data","text":"For this exercise, we are elaborating on the anomaly detection study case that is part of the unsupervised part of DS3 . Head over to that notebook, study its contents and download the accompanying dataset. You can also find the dataset at Kaggle: https://www.kaggle.com/datasets/nphantawee/pump-sensor-data Use your own dataset You can also use your own dataset, but only if it fulfills the following requirements: There is a logical (ontological, domain-specific) reason why this dataset grows over time, e.g. when more images become available every month, or new prices of something are published every day, or new network connections are delivered every week; The data you already have is large enough (contains enough instances) to be split along the lines described above, i.e. you must be able to train a model on roughly three-fifth of the dataset and test the complete pipeline at least twice on the remaining splits; In order for the model to work correctly, the data needs some kind of non trivial transformation , like removing outliers, or merging, dropping or calculating columns; Every run of the model on new data should result in an interesting plot of the data. Please check this with the teacher. The dataset contains sensor data from 1 April to 31 August 2018. We're going to train the model on the months April, May, and June and then use the trained model to predict the anomalies of the months July and August. Split the original dataset among these lines, so that eventually you have three files. We use the first of these to actually train the model, and then feed the second and third files to this persisted model sequentially.","title":"Step 1: getting and transforming the data"},{"location":"assignment5.html#step-2-create-the-model-and-the-drawer","text":"Using the first of the three splits described above, train one of the models from the notebook, or use your own realisation. Note that in order to do this training, some data-transformations are necessary. Isolate these relevant transformations, so that they can be performed later on the two remaining sets. Train the model on the transformed dataset. Use one of the techniques described on scikit-learn.org to persist the model on your local file system. Transform only the training-data For this exercise, it is imparitive that you perform the data-transformations after you split the original data and only on the training-data. In this way, we can correctly simulate the entering of future data in our pipeline. Study the method plot_sensor_anomolies(sensor, name) that you can find in the notebook . In the current setup, this method can only work if the dataframe df is defined within the scope of the complete notebook (so only if df is a global variable ). Refactor this method so that is independent of any global variables (global variables are bad news in general). Also, change its functionality so that it returns the plot instead of displaying it.","title":"Step 2: create the model and the drawer"},{"location":"assignment5.html#step-4-listening-for-new-data","text":"Now that we have trained and saved our model, it is time to put it into production. For this to work, we are going to make another class that looks at a specific directory. When a new data file is uploaded to this directory, this class will load the data in that file, apply the necessary changes and use our model to predict new new values. It then saves the transformed data with the predictions in another directory and removes the original data file. Apart from saving the transformed and enriched data, it will also create images of certain sensors and save those in the img directory \u2013 their filename displaying both the sensor and the timestamp. Have a look at the sequence diagram below to get an idea of what is happening. The whole process need to be logged in a log-file. A typical run will produce the following lines in this log-file: 2024 -06-11 10 :09:32 Found new data file 2024 -06-11 10 :09:32 Loaded the file 2024 -06-11 10 :09:34 Received transformed data 2024 -06-11 10 :09:38 Received predicions 2024 -06-11 10 :09:38 Saving predictions 2024 -06-11 10 :09:40 Saving image2 2018 -07-sensor04.png 2024 -06-11 10 :09:40 Saving image2 2018 -07-sensor51.png 2024 -06-11 10 :09:40 Resuming listening If the new file in the input -directory does not contain data that is eligable for the system, an error needs to be logged to the log-file. This should, however, not break the running of the application. Test your realisation with the two separate data files you have created \u2013 the ones containing the data for July and for August: when you put one of them in the input -directory, the whole cycle should start and create a new data file in the output -directory and a new image in the img -directory. Technical requirements all files and classes should be independent of each other: they should adhere to the SOLID-principles. the application should make use of a file application.json in which the following settings are present: the location of the input -directory the location of the output -directory the location of the img -directory the names of the sensors that needs to be drawn the interval (in seconds) with which the input -directory is checked for new files","title":"Step 4: listening for new data"}]}